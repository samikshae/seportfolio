<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Facial Emotion Detection </title>
  <link rel="stylesheet" href="style.css">
</head>
<body>

  <!-- NAVBAR -->
  <nav class="navbar">
    <div class="logo">Samiksha Emmaneni</div>
    <ul class="nav-links">
      <li><a href="index.html">Home</a></li>
      <li><a href="about.html">About</a></li>
      <li><a href="projects.html">Projects</a></li>
      <!--<li><a href="activities.html">Activities</a></li>-->
      <li><a href="contact.html">Contact</a></li>
    </ul>
  </nav>

  <!-- BACKGROUND STARS -->
  <div class="stars"></div>
  <div class="stars stars2"></div>
  <div class="stars stars3"></div>

  <!-- PROJECT DETAILS -->
  <main class="project-detail-container">
    <a href="projects.html" class="back-button">← Back to Projects</a>

    <h1>Facial Emotion Detection — Machine Learning & Computer Vision Project</h1>
    <span class="project-year">2023</span>

    <div class="project-detail-pdf">
  <iframe
    src="images/Emotion Recognition Project .pdf"
    width="100%"
    height="700px"
    style="border: none;"
  ></iframe>
</div>

    <p>
      This project explored the development of an artificial intelligence system capable of detecting human emotions by analyzing facial features. The goal was to train a neural network to classify facial expressions based on the spatial relationships between key facial landmarks, while distinguishing faces from background elements in images.
<br><br>
The system utilized 68 facial key points defined by x- and y-coordinates, enabling the calculation of Euclidean distances between facial features such as the eyes, eyebrows, and mouth. These distances served as input features for machine learning models, allowing the system to identify core emotions including happiness, sadness, anger, fear, surprise, disgust, neutral, and contempt. Feature extraction and classification techniques were applied to translate raw image data into meaningful inputs for prediction.
<br><br>
Two types of neural networks were implemented and evaluated: a multilayer perceptron (MLP) and a convolutional neural network (CNN). The MLP model processed numerical distance data through multiple dense layers using ReLU and softmax activation functions, while the CNN analyzed pixel relationships directly from images. Model performance improved with increased training epochs, and comparative analysis highlighted the strengths and limitations of feature-based versus image-based approaches in emotion classification tasks.</p>

    <!-- Optional: Embed slideshow or video -->
    <!-- <iframe src="your-slideshow-link" width="100%" height="500px"></iframe> -->
  </main>

</body>
</html>
